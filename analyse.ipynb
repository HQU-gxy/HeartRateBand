{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to read again\n",
    "FILE_NAMES = [\n",
    "    \"red_100Hz_2024-04-01_11-29-27\",\n",
    "    \"red_100Hz_2024-04-01_14-40-56\",\n",
    "    \"red_50Hz_2024-04-02_09-46-52\",\n",
    "]\n",
    "FILE_NAME = Path(FILE_NAMES[2] + \".parquet\")\n",
    "table = pq.read_table(FILE_NAME)\n",
    "# read sample rate from filename\n",
    "sample_rate_str = FILE_NAME.stem.split(\"_\")[1]\n",
    "_hz_idx = sample_rate_str.find(\"Hz\")\n",
    "sample_rate = int(sample_rate_str[:_hz_idx])\n",
    "SAMPLE_RATE = sample_rate\n",
    "SAMPLE_INTERVAL = 1 / SAMPLE_RATE\n",
    "display(f\"Sample rate: {SAMPLE_RATE} Hz\", f\"Sample interval: {SAMPLE_INTERVAL} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = table[\"red\"].to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sample rate is 800Hz (1.25ms per sample)\n",
    "xs = np.arange(0, data.shape[0] * 1.25e-3, 1.25e-3)\n",
    "# set x axis label\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Red LED Reading (ADC Value)\")\n",
    "plt.plot(xs, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "THRESHOLD = 1.5e6\n",
    "\n",
    "\n",
    "class Level(Enum):\n",
    "    LOW = auto()\n",
    "    HIGH = auto()\n",
    "\n",
    "\n",
    "Segment = tuple[int, int, Level]\n",
    "\n",
    "\n",
    "def segment_data(data: np.ndarray, threshold: float | int) -> list[Segment]:\n",
    "    last_index = 0\n",
    "    last_state = Level.HIGH if data[0] > threshold else Level.LOW\n",
    "    segments: list[Segment] = []\n",
    "    for i, n in enumerate(data):\n",
    "        if n > threshold:\n",
    "            if last_state == Level.LOW:\n",
    "                segments.append((last_index, i, Level.LOW))\n",
    "                last_index = i\n",
    "                last_state = Level.HIGH\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            if last_state == Level.HIGH:\n",
    "                segments.append((last_index, i, Level.HIGH))\n",
    "                last_index = i\n",
    "                last_state = Level.LOW\n",
    "            else:\n",
    "                continue\n",
    "        if i == len(data) - 1:\n",
    "            segments.append((last_index, i, last_state))\n",
    "    return segments\n",
    "\n",
    "segments = segment_data(data, THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_length(segment: Segment) -> int:\n",
    "    return segment[1] - segment[0]\n",
    "\n",
    "segment_lens = [segment_length(segment) for segment in segments]\n",
    "np.percentile(segment_lens, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_segments = [s for s in segments if segment_length(s) > 100]\n",
    "display(real_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high plot as red, low plot as blue\n",
    "for segment in real_segments:\n",
    "    color = \"red\" if segment[2] == Level.HIGH else \"blue\"\n",
    "    plt.axvspan(segment[0] * 1.25e-3, segment[1] * 1.25e-3, color=color, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# we're only interested in the high segments\n",
    "high_segments_idx = [s for s in real_segments if s[2] == Level.HIGH]\n",
    "display(high_segments_idx)\n",
    "high_segments = [data[s[0]:s[1]] for s in high_segments_idx]\n",
    "\n",
    "# lucky = random.sample(high_segments, 1)[0]\n",
    "# lucky_idx = random.randint(0, len(high_segments) - 1)\n",
    "lucky_idx = 0\n",
    "display(f\"lucky index: {lucky_idx}\")\n",
    "# 2 might be a good one\n",
    "# 1484 : 70_000\n",
    "lucky = high_segments[lucky_idx]\n",
    "# filter out below 1 percentile and above 99 percentile\n",
    "# filtered_lucky = np.clip(lucky, np.percentile(lucky, 1),\n",
    "#                          np.percentile(lucky, 99))\n",
    "# TODO: maybe doing some edge detection\n",
    "# like 1D canny\n",
    "# I don't feel the necessity if DC offset is removed (we have different significant DC offset)\n",
    "xs = np.array(range(len(lucky)))\n",
    "xs_time = xs * SAMPLE_INTERVAL\n",
    "# px.line(y=lucky, x=xs).show()\n",
    "trace = go.Scatter(x=xs, y=lucky, mode=\"lines\")\n",
    "trace_time = go.Scatter(x=xs_time, y=lucky, mode=\"lines\")\n",
    "fig = go.Figure(data=[trace_time, trace])\n",
    "# https://community.plotly.com/t/can-plotly-support-2-x-axis-and-2-y-axis-in-one-graph/38303/2\n",
    "fig.update_layout(\n",
    "    xaxis=dict(title=\"Sample Index\"),\n",
    "    yaxis=dict(title=\"Red LED Reading (ADC Value)\"),\n",
    "    xaxis2=dict(title=\"Time (s)\", overlaying=\"x\", side=\"top\"),\n",
    ")\n",
    "fig.data[0].update(xaxis=\"x2\", yaxis=\"y\", line=dict(color=\"rgba(0,0,0,0)\")) # type: ignore\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "workable_data:Optional[np.ndarray] = lucky\n",
    "# if FILE_NAME.stem == \"red_100Hz_2024-04-01_11-29-27\":\n",
    "#     if lucky_idx == 1:\n",
    "#         workable_data = lucky[4299:-100]\n",
    "#     if lucky_idx == 2:\n",
    "#         workable_data = lucky[765:-50]\n",
    "#     if lucky_idx == 6:\n",
    "#         workable_data = lucky[1678:-200]\n",
    "\n",
    "xs_time = np.array(range(len(workable_data))) * SAMPLE_INTERVAL # type: ignore\n",
    "px.line(y=workable_data, x=xs_time).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heartpy as hp\n",
    "from scipy.signal import butter, detrend, filtfilt, iirnotch, savgol_filter, wiener, sosfilt, sosfiltfilt, freqz, sosfreqz, ellip\n",
    "from scipy.io import loadmat\n",
    "from heartpy import filter_signal\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.ellip.html\n",
    "\n",
    "mat = loadmat(\"HR_filter_ba.2.50Hz.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_2 = mat[\"b\"].flatten()\n",
    "a_2 = mat[\"a\"].flatten()\n",
    "display({\n",
    "    \"b\": b_2,\n",
    "    \"a\": a_2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy_bp_2 = butter(1, [0.8, 5], btype=\"band\", fs=SAMPLE_RATE, output=\"sos\")\n",
    "b_s_2, a_s_2 = butter(1, [0.8, 5], btype=\"band\", fs=SAMPLE_RATE, output=\"ba\")\n",
    "filtered_scipy = sosfiltfilt(scipy_bp_2, workable_data)\n",
    "\n",
    "display(f\"scipy: {b_s_2.shape}, {a_s_2.shape}\")\n",
    "display(f\"matlab 2nd order: {b_2.shape}, {a_2.shape}\")\n",
    "# in scipy 2nd order is the 4th order in matlab\n",
    "\n",
    "worN = 4000\n",
    "\n",
    "w, h = sosfreqz(scipy_bp_2, worN=worN)\n",
    "w_2, h_2 = freqz(b_2, a_2, worN=worN)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_title(\"Digital filter frequency response\")\n",
    "ax1.set_ylabel(\"Amplitude (ratio)\")\n",
    "ax1.set_xlabel(\"Frequency (Hz)\")\n",
    "ax1.grid()\n",
    "ax1.set_xlim([0, 10])\n",
    "\n",
    "ax1.plot(0.5 * SAMPLE_RATE * w / np.pi, np.abs(h), label=\"scipy (2nd order)\")\n",
    "ax1.plot(0.5 * SAMPLE_RATE * w_2 / np.pi,\n",
    "         np.abs(h_2),\n",
    "         label=\"matlab (2nd order) ellip\")\n",
    "\n",
    "# some how the matlab filter is significantly worse than scipy\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.4Hz to 100Hz\n",
    "# https://github.com/paulvangentcom/heartrate_analysis_python/blob/master/examples/1_regular_PPG/Analysing_a_PPG_signal.ipynb\n",
    "# https://github.com/paulvangentcom/heartrate_analysis_python/blob/master/examples/5_noisy_ECG/Analysing_Noisy_ECG.ipynb\n",
    "# https://github.com/paulvangentcom/heartrate_analysis_python/blob/master/docs/algorithmfunctioning.rst\n",
    "# https://github.com/paulvangentcom/heartrate_analysis_python/blob/master/docs/heartrateanalysis.rst\n",
    "\n",
    "# remove_baseline_wander is just a notch filter applied to low frequency (to remove DC offset)\n",
    "# notch filter to remove DC offset\n",
    "# enhance_ecg_peaks is useless\n",
    "# the high pass/low pass/band pass filter here are all butterworth filter\n",
    "\n",
    "# We will use the bandpass variant.\n",
    "# we filter out frequencies below 0.8Hz (<= 48 bpm) (bpm = 60 x Hz)\n",
    "# and above 3Hz (>= 180 bpm)\n",
    "# Second-order sections (SOS) matrix and gain values (G) from MATLAB\n",
    "\n",
    "# by default it only has 2nd order filter\n",
    "\n",
    "filtered_mat = filtfilt(b_2, a_2, workable_data)\n",
    "filtered_scipy = sosfiltfilt(scipy_bp_2, workable_data)\n",
    "\n",
    "# drop the rediculously high values\n",
    "# I'm not sure about the value range\n",
    "filtered_scipy = np.clip(filtered_scipy, -255, 255 - 1)\n",
    "filtered_mat = np.clip(filtered_mat, -255, 255 - 1)\n",
    "\n",
    "trace_bp_matlab = go.Scatter(x=xs_time,\n",
    "                               y=filtered_mat,\n",
    "                               mode=\"lines\",\n",
    "                               name=\"Bandpass Filtered (MATLAB)\")\n",
    "trace_bp = go.Scatter(x=xs_time,\n",
    "                      y=filtered_scipy,\n",
    "                      mode=\"lines\",\n",
    "                      name=\"Bandpass Filtered (Scipy)\")\n",
    "fig = go.Figure(data=[trace_bp, trace_bp_matlab])\n",
    "fig.update_layout(\n",
    "    xaxis=dict(title=\"Time (s)\"),\n",
    "    yaxis=dict(title=\"Red LED Reading (ADC Value)\"),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is stupid, we just find the minimum value\n",
    "# bl_val = np.percentile(filtered_mat, 0.1)\n",
    "from audioop import reverse\n",
    "from typing import Sequence\n",
    "\n",
    "NDArray = np.ndarray\n",
    "number = int | float\n",
    "\n",
    "bl_val = np.min(filtered_mat)\n",
    "display(f\"Baseline value: {bl_val}\")\n",
    "working_data = filtered_mat.copy()\n",
    "if bl_val < 0:\n",
    "    working_data = working_data + abs(bl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from typing import Tuple\n",
    "\n",
    "# https://leetcode.cn/problems/sliding-window-median\n",
    "# https://ipython-books.github.io/47-implementing-an-efficient-rolling-average-algorithm-with-stride-tricks/\n",
    "# https://aman.ai/code/sliding-window/\n",
    "# https://oi-wiki.org/ds/monotonous-queue/\n",
    "\n",
    "\n",
    "# np.pad(input, (size_before, size_after), mode=\"edge\")\n",
    "# https://github.com/scipy/scipy/blob/2ecac3e596fdb458c85000e7707a8f5f46926621/scipy/ndimage/src/ni_support.c#L222\n",
    "def extend_input(input: NDArray, size_before: int,\n",
    "                 size_after: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    abcd -> abcdcba | abcd | dcbabcd\n",
    "    \"\"\"\n",
    "    line_len = len(input)\n",
    "    before_size_diff = line_len - size_before\n",
    "    # [::-1] is python way to reverse (I prefer use `reversed` though)\n",
    "\n",
    "    if size_before != 0:\n",
    "        before = input[:size_before][::-1]\n",
    "        if before_size_diff < 0:\n",
    "            sz = abs(before_size_diff)\n",
    "            before = np.concatenate([before, input[:sz][::-1]])\n",
    "    else:\n",
    "        before = np.array([])\n",
    "\n",
    "    if size_after != 0:\n",
    "        after_size_diff = line_len - size_after\n",
    "        after = input[-size_after:][::-1]\n",
    "        if after_size_diff < 0:\n",
    "            sz = abs(after_size_diff)\n",
    "            after = np.concatenate([after, input[:sz][::-1]])\n",
    "    else:\n",
    "        after = np.array([])\n",
    "\n",
    "    return np.concatenate([before, input, after])\n",
    "\n",
    "\n",
    "def rolling_mean(input: NDArray, window_size: int) -> Tuple[NDArray, number]:\n",
    "    \"\"\"\n",
    "    input: 1D array\n",
    "    window_size: window size\n",
    "    \"\"\"\n",
    "    assert window_size > 0, \"Window size must be greater than 0\"\n",
    "    size_1 = int(window_size / 2)\n",
    "    size_2 = window_size - size_1 - 1\n",
    "    padded = extend_input(input, size_1, size_2)\n",
    "    var_summation = np.sum(padded[:window_size])\n",
    "    output = np.zeros_like(input)\n",
    "    div = var_summation / window_size\n",
    "    output[0] = div\n",
    "\n",
    "    summation = div\n",
    "    # no idea how these crazy size aligns\n",
    "    for i in range(window_size, len(padded)):\n",
    "        var_summation += padded[i]\n",
    "        var_summation -= padded[i - window_size]\n",
    "        div = var_summation / window_size\n",
    "        summation += div\n",
    "        output[i - window_size + 1] = div\n",
    "\n",
    "    approx_mean = summation / len(input)\n",
    "    return output, approx_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "class TestRollingMean(unittest.TestCase):\n",
    "\n",
    "    def test_sz(self):\n",
    "        input_array = np.array([1, 2, 3, 4, 5])\n",
    "        r, a = rolling_mean(input_array, 3)\n",
    "        self.assertEqual(len(r), len(input_array))\n",
    "    \n",
    "    def test_approx_mean(self):\n",
    "        input_array = np.array([1, 2, 3, 4, 5, 52])\n",
    "        r, a = rolling_mean(input_array, 10)\n",
    "        np.testing.assert_almost_equal(a, np.mean(input_array), decimal=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TestExtendInput(unittest.TestCase):\n",
    "\n",
    "    def test_normal_case(self):\n",
    "        \"\"\"Test case where size_before and size_after are less than the array length\"\"\"\n",
    "        input_array = np.array([1, 2, 3, 4])\n",
    "        expected_output = np.array([2, 1, 1, 2, 3, 4, 4, 3])\n",
    "        np.testing.assert_array_equal(extend_input(input_array, 2, 2),\n",
    "                                      expected_output)\n",
    "\n",
    "    def test_size_before_larger(self):\n",
    "        \"\"\"Test case where size_before is larger than the array length\"\"\"\n",
    "        input_array = np.array([1, 2, 3, 4])\n",
    "        expected_output = np.array([4, 3, 2, 1, 1, 1, 2, 3, 4, 4, 3])\n",
    "        np.testing.assert_array_equal(extend_input(input_array, 5, 2),\n",
    "                                      expected_output)\n",
    "\n",
    "    def test_size_after_larger(self):\n",
    "        \"\"\"Test case where size_after is larger than the array length\"\"\"\n",
    "        input_array = np.array([1, 2, 3, 4])\n",
    "        expected_output = np.array([2, 1, 1, 2, 3, 4, 4, 3, 2, 1, 1])\n",
    "        np.testing.assert_array_equal(extend_input(input_array, 2, 5),\n",
    "                                      expected_output)\n",
    "\n",
    "    def test_both_sizes_larger(self):\n",
    "        \"\"\"Test case where size_before and size_after are larger than the array length\"\"\"\n",
    "        input_array = np.array([1, 2, 3, 4])\n",
    "        expected_output = np.array([4, 3, 2, 1, 1, 1, 2, 3, 4, 4, 3, 2, 1, 1])\n",
    "        np.testing.assert_array_equal(extend_input(input_array, 5, 5),\n",
    "                                      expected_output)\n",
    "\n",
    "    def test_empty_array(self):\n",
    "        \"\"\"Test case where the input array is empty\"\"\"\n",
    "        input_array = np.array([])\n",
    "        expected_output = np.array([])\n",
    "        np.testing.assert_array_equal(extend_input(input_array, 2, 2),\n",
    "                                      expected_output)\n",
    "\n",
    "    def test_zero_sizes(self):\n",
    "        \"\"\"Test case where size_before and size_after are zero\"\"\"\n",
    "        input_array = np.array([1, 2, 3, 4])\n",
    "        expected_output = np.array([1, 2, 3, 4])\n",
    "        np.testing.assert_array_equal(extend_input(input_array, 0, 0),\n",
    "                                      expected_output)\n",
    "\n",
    "    def test_zero_size_before(self):\n",
    "        \"\"\"Test case where size_before is zero and size_after is larger than the array length\"\"\"\n",
    "        input_array = np.array([1, 2, 3, 4])\n",
    "        expected_output = np.array([1, 2, 3, 4, 4, 3, 2, 1, 1])\n",
    "        np.testing.assert_array_equal(extend_input(input_array, 0, 5),\n",
    "                                      expected_output)\n",
    "\n",
    "    def test_zero_size_after(self):\n",
    "        \"\"\"Test case where size_before is larger than the array length and size_after is zero\"\"\"\n",
    "        input_array = np.array([1, 2, 3, 4])\n",
    "        expected_output = np.array([4, 3, 2, 1, 1, 1, 2, 3, 4])\n",
    "        np.testing.assert_array_equal(extend_input(input_array, 5, 0),\n",
    "                                      expected_output)\n",
    "\n",
    "    def test_single_element_array(self):\n",
    "        \"\"\"Test case where the input array has a single element\"\"\"\n",
    "        input_array = np.array([1])\n",
    "        expected_output = np.array([1, 1, 1])\n",
    "        np.testing.assert_array_equal(extend_input(input_array, 1, 1),\n",
    "                                      expected_output)\n",
    "\n",
    "\n",
    "unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baby_detect_peaks(hrdata: NDArray, rol_mean: NDArray, ma_perc: number):\n",
    "    rmean = np.array(rol_mean)\n",
    "    rol_mean = rmean + ((rmean) * ma_perc)\n",
    "\n",
    "    mn = np.mean(rmean) * ma_perc\n",
    "    rol_mean = rmean + mn\n",
    "\n",
    "    peaksx = np.where((hrdata > rol_mean))[0]\n",
    "    peaksy = hrdata[peaksx]\n",
    "    peakedges = np.concatenate(\n",
    "        (np.array([0]), (np.where(np.diff(peaksx) > 1)[0]),\n",
    "         np.array([len(peaksx)])))\n",
    "    peaklist = []\n",
    "\n",
    "    for i in range(0, len(peakedges) - 1):\n",
    "        try:\n",
    "            y_values = peaksy[peakedges[i]:peakedges[i + 1]].tolist()\n",
    "            peaklist.append(peaksx[peakedges[i] +\n",
    "                                   y_values.index(max(y_values))])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return np.array(peaklist)\n",
    "\n",
    "\n",
    "def detect_peaks(hr_data: NDArray, rol_mean: NDArray, mean: number,\n",
    "                 ma_perc: number):\n",
    "    assert len(hr_data) == len(\n",
    "        rol_mean), \"Length of input data and rolling mean must be the same\"\n",
    "    assert ma_perc > 0, \"Percentage must be greater than 0\"\n",
    "    assert 0 < ma_perc < 2, \"Percentage must be between 0 and 2 (0.1 means 10% of the peak value)\"\n",
    "\n",
    "    mn = mean * ma_perc\n",
    "    rmean = rol_mean + rol_mean * ma_perc + mn\n",
    "\n",
    "    idx = np.arange(0, len(hr_data))\n",
    "    idx_data = np.vstack((idx, hr_data)).T\n",
    "    peaks_pair = idx_data[np.where((hr_data > rmean))]\n",
    "\n",
    "    with_ends = np.vstack([[0, hr_data[0]], peaks_pair,\n",
    "                           [len(hr_data) - 1, hr_data[-1]]])\n",
    "\n",
    "    peak_list = np.array([], dtype=int)\n",
    "\n",
    "    for i, pair in enumerate(with_ends):\n",
    "        if i + 1 >= len(with_ends):\n",
    "            break\n",
    "        next_pair = with_ends[i + 1]\n",
    "        x_0 = int(pair[0])\n",
    "        x_1 = int(next_pair[0])\n",
    "        pair_interval = idx_data[x_0:x_1]\n",
    "        if len(pair_interval) == 0 or len(pair_interval) == 1:\n",
    "            continue\n",
    "        max_idx = np.argmax(pair_interval[:, 1])\n",
    "        origin_idx = int(pair_interval[max_idx][0])\n",
    "        peak_list = np.append(peak_list, int(origin_idx))\n",
    "\n",
    "    return peak_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need 0.75s (at some sample rate)\n",
    "window_size = int(0.75 / SAMPLE_INTERVAL)\n",
    "r, a = rolling_mean(filtered_mat, window_size)\n",
    "display(\n",
    "    f\"Window size: {window_size}, Approximate mean: {a}, data mean: {np.mean(filtered_mat)}, rolling mean: {np.mean(r)}\"\n",
    ")\n",
    "# ma_perc_list = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.5, 2, 3]\n",
    "ma_perc_list = [0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.5]\n",
    "\n",
    "detect_peaks(filtered_mat, r, a, 0.3)\n",
    "baby_detect_peaks(filtered_mat, r, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_freq: whether to calculate frequency domain measures\n",
    "# interp_threshold: the amplitude threshold beyond which will be checked for\n",
    "# clipping. Recommended is to take this as the maximum value of the ADC with\n",
    "# some margin for signal noise\n",
    "# reject_segmentwise: whether to reject segments with more than 30% rejected\n",
    "# beats. By default looks at segments of 10 beats at a time.\n",
    "\n",
    "# clean_rr uses by default quotient-filtering, which is a bit aggressive.\n",
    "# You can set 'iqr' or 'z-score' with the clean_rr_method flag.\n",
    "from typing import Literal\n",
    "\n",
    "CLEAN_RR_METHOD = Literal[\"quotient-filter\", \"iqr\", \"z-score\"]\n",
    "clean_rr_method: CLEAN_RR_METHOD = \"iqr\"\n",
    "working, measures = hp.process(\n",
    "    filtered_mat,\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    interp_clipping=False,\n",
    "    clean_rr=False,\n",
    "    clean_rr_method=clean_rr_method,\n",
    ")\n",
    "\n",
    "# Take into consideration that the scale for RMSSD doesn't typically exceed +/-\n",
    "# 130, SDSD doesn't differ by much. This means that even a few incorrectly\n",
    "# detected peaks are already introducing large measurement errors into the output\n",
    "# variables. The algorithm described here is specifically designed to handle noisy\n",
    "# PPG data from cheap sensors. The main design criteria was to minimise the number\n",
    "# of incorrectly placed peaks as to minimise the error introduced into the output\n",
    "# measures.\n",
    "\n",
    "display(measures)\n",
    "hp.plotter(working, measures, figsize=(18, 4), moving_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.plot_breathing(working, measures, figsize=(18, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.plot_poincare(working, measures, figsize=(4, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
