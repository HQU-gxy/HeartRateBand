{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to read again\n",
    "table = pq.read_table(\"red.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = table[\"red\"].to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SAMPLE_RATE = 800\n",
    "# sample rate is 800Hz (1.25ms per sample)\n",
    "xs = np.arange(0, data.shape[0] * 1.25e-3, 1.25e-3)\n",
    "# set x axis label\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Red LED Reading (ADC Value)\")\n",
    "plt.plot(xs, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "THRESHOLD = 1.5e6\n",
    "\n",
    "\n",
    "class Level(Enum):\n",
    "    LOW = auto()\n",
    "    HIGH = auto()\n",
    "\n",
    "\n",
    "Segment = tuple[int, int, Level]\n",
    "\n",
    "\n",
    "def segment_data(data: np.ndarray, threshold: float | int) -> list[Segment]:\n",
    "    last_index = 0\n",
    "    last_state = Level.HIGH if data[0] > threshold else Level.LOW\n",
    "    segments: list[Segment] = []\n",
    "    for i, n in enumerate(data):\n",
    "        if n > threshold:\n",
    "            if last_state == Level.LOW:\n",
    "                segments.append((last_index, i, Level.LOW))\n",
    "                last_index = i\n",
    "                last_state = Level.HIGH\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            if last_state == Level.HIGH:\n",
    "                segments.append((last_index, i, Level.HIGH))\n",
    "                last_index = i\n",
    "                last_state = Level.LOW\n",
    "            else:\n",
    "                continue\n",
    "        if i == len(data) - 1:\n",
    "            segments.append((last_index, i, last_state))\n",
    "    return segments\n",
    "\n",
    "segments = segment_data(data, THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_length(segment: Segment) -> int:\n",
    "    return segment[1] - segment[0]\n",
    "\n",
    "segment_lens = [segment_length(segment) for segment in segments]\n",
    "np.percentile(segment_lens, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_segments = [s for s in segments if segment_length(s) > 100]\n",
    "display(real_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high plot as red, low plot as blue\n",
    "for segment in real_segments:\n",
    "    color = \"red\" if segment[2] == Level.HIGH else \"blue\"\n",
    "    plt.axvspan(segment[0] * 1.25e-3, segment[1] * 1.25e-3, color=color, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# we're only interested in the high segments\n",
    "high_segments_idx = [s for s in real_segments if s[2] == Level.HIGH]\n",
    "display(high_segments_idx)\n",
    "high_segments = [data[s[0]:s[1]] for s in high_segments_idx]\n",
    "\n",
    "# lucky = random.sample(high_segments, 1)[0]\n",
    "# lucky_idx = random.randint(0, len(high_segments) - 1)\n",
    "lucky_idx = 0\n",
    "display(f\"lucky index: {lucky_idx}\")\n",
    "# 2 might be a good one\n",
    "# 1484 : 70_000\n",
    "lucky = high_segments[lucky_idx]\n",
    "# filter out below 1 percentile and above 99 percentile\n",
    "# filtered_lucky = np.clip(lucky, np.percentile(lucky, 1),\n",
    "#                          np.percentile(lucky, 99))\n",
    "# TODO: maybe doing some edge detection\n",
    "# like 1D canny\n",
    "# I don't feel the necessity if DC offset is removed (we have different significant DC offset)\n",
    "# px.line(y=lucky).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0\n",
    "# workable_data = high_segments[0][1192:67_300]\n",
    "# workable_data = high_segments[0][12192:67_300]\n",
    "workable_data = high_segments[0][68_401:79_000]\n",
    "# 1\n",
    "# workable_data = high_segments[1][1009:9530]\n",
    "# workable_data = high_segments[1][11_387:42_097]\n",
    "# workable_data = high_segments[1][14_000:14_000+16_000]\n",
    "# 2 is unusable (maybe?)\n",
    "# workable_data = high_segments[2][5885:70_000]\n",
    "# workable_data = high_segments[2][2994:2994+16_000]\n",
    "# 3 is unusable (can almost confirm there's no valid signal)\n",
    "# workable_data = high_segments[3][1536:19_000]\n",
    "\n",
    "# a window of 10k at 800Hz seems to be a optimal window size\n",
    "# HF power is usually computed over a minimum of 1 minute of good signal\n",
    "# workable_data = high_segments[0][40_000:40_000+10_000]\n",
    "# workable_data = high_segments[0][30_000:30_000+10_000]\n",
    "\n",
    "# remove DC offset\n",
    "# detrended = detrend(workable_data)\n",
    "px.line(y=workable_data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import detrend\n",
    "import heartpy as hp\n",
    "from scipy.signal import wiener\n",
    "\n",
    "# 0.4Hz to 100Hz\n",
    "# https://github.com/paulvangentcom/heartrate_analysis_python/blob/master/examples/1_regular_PPG/Analysing_a_PPG_signal.ipynb\n",
    "# https://github.com/paulvangentcom/heartrate_analysis_python/blob/master/examples/5_noisy_ECG/Analysing_Noisy_ECG.ipynb\n",
    "# https://github.com/paulvangentcom/heartrate_analysis_python/blob/master/docs/algorithmfunctioning.rst\n",
    "# https://github.com/paulvangentcom/heartrate_analysis_python/blob/master/docs/heartrateanalysis.rst\n",
    "\n",
    "# remove_baseline_wander is just a notch filter applied to low frequency (to remove DC offset)\n",
    "# notch filter to remove DC offset\n",
    "w_filtered = hp.filter_signal(workable_data, sample_rate=SAMPLE_RATE, filtertype=\"notch\", order=2, cutoff=0.005, return_top=False)\n",
    "# enhance_ecg_peaks is useless\n",
    "# the high pass/low pass/band pass filter here are all butterworth filter\n",
    "\n",
    "# We will use the bandpass variant.\n",
    "# we filter out frequencies below 0.8Hz (<= 48 bpm) (bpm = 60 x Hz)\n",
    "# and above 3Hz (>= 180 bpm)\n",
    "w_filtered = hp.filter_signal(w_filtered, sample_rate=SAMPLE_RATE, filtertype=\"bandpass\", order=3, cutoff=(0.7, 6), return_top=False)\n",
    "# w_filtered = hp.filter_signal(w_filtered, sample_rate=SAMPLE_RATE, filtertype=\"lowpass\", order=3, cutoff=6, return_top=False)\n",
    "w_filtered = hp.scale_data(w_filtered)\n",
    "px.line(y=w_filtered).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_freq: whether to calculate frequency domain measures\n",
    "# interp_threshold: the amplitude threshold beyond which will be checked for\n",
    "# clipping. Recommended is to take this as the maximum value of the ADC with\n",
    "# some margin for signal noise\n",
    "# reject_segmentwise: whether to reject segments with more than 30% rejected\n",
    "# beats. By default looks at segments of 10 beats at a time.\n",
    "\n",
    "# clean_rr uses by default quotient-filtering, which is a bit aggressive.\n",
    "# You can set 'iqr' or 'z-score' with the clean_rr_method flag.\n",
    "working, measures = hp.process(w_filtered, sample_rate=SAMPLE_RATE, freq_method=\"welch\", interp_clipping=True, clean_rr_method=\"quotient-filtering\")\n",
    "\n",
    "# Take into consideration that the scale for RMSSD doesn't typically exceed +/-\n",
    "# 130, SDSD doesn't differ by much. This means that even a few incorrectly\n",
    "# detected peaks are already introducing large measurement errors into the output\n",
    "# variables. The algorithm described here is specifically designed to handle noisy\n",
    "# PPG data from cheap sensors. The main design criteria was to minimise the number\n",
    "# of incorrectly placed peaks as to minimise the error introduced into the output\n",
    "# measures.\n",
    "\n",
    "display(measures)\n",
    "hp.plotter(working, measures, figsize=(18, 4), moving_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.plot_breathing(working, measures, figsize=(18, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.plot_poincare(working, measures, figsize=(4, 4))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
